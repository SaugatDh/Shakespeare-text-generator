{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2170698a"
      },
      "source": [
        "Downloads the Tiny Shakespeare dataset from a URL using `tf.keras.utils.get_file` and reads it into a string variable `shakespeare_text`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44f5b144",
        "outputId": "4c47d074-64be-4888-a6b4-dfece2eae1cf"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "shakespear_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "filepath = tf.keras.utils.get_file(\"shakespeare.txt\",shakespear_url)\n",
        "with open(filepath) as f:\n",
        "  shakespeare_text = f.read()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1607dc58"
      },
      "source": [
        "Prints the first 80 characters of the downloaded Shakespeare text to get a preview of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ba8cbc7",
        "outputId": "0e2f1b58-e979-499f-b774-8b572724eb99"
      },
      "source": [
        "print(shakespeare_text[:80])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ef701c7"
      },
      "source": [
        "Initializes a `TextVectorization` layer for character-level tokenization, adapts it to the Shakespeare text to build the vocabulary, and then encodes the text into a sequence of character IDs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b358f036"
      },
      "source": [
        "text_vec_layer = tf.keras.layers.TextVectorization(split=\"character\",standardize=\"lower\")\n",
        "text_vec_layer.adapt([shakespeare_text])\n",
        "encoded = text_vec_layer([shakespeare_text])[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e09abdd5"
      },
      "source": [
        "Adjusts the encoded character IDs by subtracting 2 and calculates the number of unique tokens in the vocabulary after the adjustment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30e61a37"
      },
      "source": [
        "encoded -= 2\n",
        "n_tokens = text_vec_layer.vocabulary_size() -2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b988ee38"
      },
      "source": [
        "Defines a function `to_dataset` that takes a sequence of character IDs and converts it into a TensorFlow Dataset of input/target window pairs for training a sequence model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cfc62ec"
      },
      "source": [
        "def to_dataset(sequence,length,shuffle=False,seed=None,batch_size=32):\n",
        "  ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
        "  ds = ds.window(length + 1,shift=1,drop_remainder=True)\n",
        "  ds = ds.flat_map(lambda window_ds:window_ds.batch(length+1))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=100_00,seed=seed)\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds.map(lambda window: (window[:,:-1],window[:,1:])).prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fa50b12"
      },
      "source": [
        "Sets the window length for the dataset and splits the encoded text into training, validation, and test sets using the `to_dataset` function with specified sizes and shuffling for the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "580fa00d"
      },
      "source": [
        "length =100\n",
        "tf.random.set_seed(42)\n",
        "train_set = to_dataset(encoded[:1_000_000],length=length,shuffle=True,seed=42)\n",
        "valid_set = to_dataset(encoded[1_000_000:1_060_000],length=length)\n",
        "test_set = to_dataset(encoded[1_060_000:],length=length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfcacfe6"
      },
      "source": [
        "Builds a character-level RNN model using a GRU layer for sequence processing, followed by a Dense layer with softmax activation for character prediction. Compiles the model with sparse categorical crossentropy loss and Nadam optimizer, and sets up a ModelCheckpoint callback to save the best model based on validation accuracy during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f897a0e"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=n_tokens,output_dim=16),\n",
        "    tf.keras.layers.GRU(128,return_sequences=True),\n",
        "    tf.keras.layers.Dense(n_tokens,activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='nadam',metrics=['accuracy'])\n",
        "\n",
        "# model_ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
        "#     \"shakespeare_model.keras\",monitor =\"val_accuracy\",save_best_only=True\n",
        "# )\n",
        "\n",
        "# history = model.fit(train_set,validation_data=valid_set,epochs=10,callbacks=[model_ckpt])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# As training takes a lot of time, we are using the pretained model of shakespeare RNN model"
      ],
      "metadata": {
        "id": "T0rnXN-bdH5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import tensorflow as tf\n",
        "\n"
      ],
      "metadata": {
        "id": "ACDsS5OQdxhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "shakespeare_model = tf.keras.Sequential([\n",
        "    text_vec_layer,\n",
        "    tf.keras.layers.Lambda(lambda X: X - 2),  # no <PAD> or <UNK> tokens\n",
        "    model\n",
        "])"
      ],
      "metadata": {
        "id": "YhiNmUYGqffp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://github.com/ageron/data/raw/main/shakespeare_model.tgz\"\n",
        "path = tf.keras.utils.get_file(\"shakespeare_model.tgz\",url,extract=True)\n",
        "model_path = pathlib.Path(path).with_suffix('').joinpath('shakespeare_model')"
      ],
      "metadata": {
        "id": "SlbUoa7gDBYo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e131b261-2fa2-4265-911b-957ef8ddd524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/ageron/data/raw/main/shakespeare_model.tgz\n",
            "\u001b[1m352865/352865\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8C7Gm7FDffY",
        "outputId": "5866d4d9-13b9-4d70-ac38-78c9c90215f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/root/.keras/datasets/shakespeare_model_extracted/shakespeare_model')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.TFSMLayer(\n",
        "        model_path,\n",
        "        call_endpoint='serving_default'\n",
        "    )\n",
        "])"
      ],
      "metadata": {
        "id": "O4HmP6PRDk_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded = tf.saved_model.load(model_path)\n"
      ],
      "metadata": {
        "id": "c9SZ_GcwDq25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Available signatures:\", list(loaded.signatures.keys()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeBCNN3iF9R0",
        "outputId": "580718b2-2349-4c94-fe3f-c0cc5589a32f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available signatures: ['serving_default']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "infer = None\n",
        "if \"serving_default\" in loaded.signatures:\n",
        "    infer = loaded.signatures[\"serving_default\"]\n",
        "else:\n",
        "    # fallback to direct call\n",
        "    infer = loaded.__call__"
      ],
      "metadata": {
        "id": "yAFZ3yU0H3pO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input(shape=(), dtype=tf.string)  # say input is a string\n"
      ],
      "metadata": {
        "id": "dxU1pnQwJcp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = text_vec_layer(inputs)          # shape (batch, seq_len)\n"
      ],
      "metadata": {
        "id": "V49O2BP7IAWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.keras.layers.Lambda(lambda X: X - 2)(x)\n"
      ],
      "metadata": {
        "id": "TFdgaRAAIBfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = tf.constant([\"To be or not to b\"])\n",
        "# Pass the raw string prompt directly to the infer function\n",
        "outputs = infer(text_vectorization_input=prompt)\n",
        "logits = outputs['sequential']  # or outputs['output_0'] depending on signature"
      ],
      "metadata": {
        "id": "693tt-fGICoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4M_OHZZOCS7",
        "outputId": "686bb14a-42fd-4144-ad27-1c4f5efb7119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 17, 39), dtype=float32, numpy=\n",
              "array([[[1.81564420e-01, 6.64177835e-02, 6.29598368e-03, 1.06545582e-01,\n",
              "         2.56400704e-02, 7.74683729e-02, 3.66694510e-01, 4.69604880e-03,\n",
              "         3.51578742e-02, 1.17589188e-05, 9.23981145e-03, 1.84964836e-02,\n",
              "         5.56145551e-07, 1.79435108e-02, 2.96746759e-04, 6.57376461e-03,\n",
              "         1.29411472e-02, 2.60792095e-02, 1.12853968e-03, 9.53492636e-05,\n",
              "         1.11382235e-06, 1.23063161e-04, 1.17037678e-03, 9.44407936e-03,\n",
              "         2.98096296e-07, 3.17247277e-08, 1.23338113e-02, 5.36633283e-03,\n",
              "         1.70396850e-03, 3.56346485e-03, 1.34389906e-03, 1.66126655e-03,\n",
              "         5.96528480e-07, 1.22643706e-09, 1.27851008e-09, 1.44478605e-07,\n",
              "         6.61341926e-10, 4.58126641e-19, 9.39734601e-09],\n",
              "        [7.48781800e-01, 8.53533311e-06, 1.50150327e-05, 1.44324657e-02,\n",
              "         8.39594850e-06, 7.65351229e-04, 2.05993449e-04, 6.82524929e-04,\n",
              "         7.88733885e-02, 2.04552896e-02, 1.16906092e-02, 1.67817809e-02,\n",
              "         1.00985417e-05, 1.16156172e-02, 1.32352943e-02, 9.40741032e-08,\n",
              "         1.40419742e-02, 1.63870975e-02, 4.55427507e-04, 1.57159215e-04,\n",
              "         1.22141745e-03, 3.30902846e-03, 3.66414926e-04, 1.35832960e-02,\n",
              "         3.87549062e-06, 2.48537367e-06, 7.70108867e-03, 1.02849249e-02,\n",
              "         1.89475669e-03, 2.11326894e-03, 3.32344847e-04, 1.04701445e-02,\n",
              "         1.28608759e-08, 2.43635174e-08, 1.08163098e-04, 4.82917812e-06,\n",
              "         1.49593640e-12, 1.90484735e-20, 1.42422052e-16],\n",
              "        [1.41632772e-05, 7.60129420e-03, 1.24783017e-01, 1.04637686e-02,\n",
              "         6.27920404e-02, 3.76665480e-02, 6.60941154e-02, 7.14723468e-02,\n",
              "         7.07934657e-03, 6.69007236e-03, 3.41560303e-06, 2.33795531e-02,\n",
              "         6.96957856e-02, 1.09784603e-02, 1.20131016e-01, 1.51824933e-02,\n",
              "         6.15264662e-02, 1.24427806e-05, 6.80198893e-02, 3.41177657e-02,\n",
              "         3.18163745e-02, 6.71970174e-02, 7.17041939e-02, 3.30160583e-06,\n",
              "         1.85538009e-02, 1.68983138e-03, 4.28117664e-06, 1.29903061e-03,\n",
              "         5.99755458e-06, 1.52754058e-06, 3.92893617e-06, 1.05586514e-05,\n",
              "         6.72447914e-03, 3.25351302e-03, 2.24984797e-05, 5.71279134e-06,\n",
              "         2.45352627e-10, 5.50657271e-14, 2.18984921e-18],\n",
              "        [2.72154853e-06, 7.30624557e-01, 3.12322079e-08, 2.32346375e-02,\n",
              "         4.75786813e-02, 2.50117108e-02, 5.87859761e-09, 2.85200997e-07,\n",
              "         8.31195116e-02, 2.80776731e-04, 1.25572965e-08, 1.98387206e-02,\n",
              "         2.55295096e-09, 5.36180586e-02, 5.75829631e-07, 1.66848302e-02,\n",
              "         2.08140682e-06, 1.34895686e-07, 6.21054666e-11, 7.63254263e-07,\n",
              "         5.53494583e-10, 2.72109048e-07, 2.39208986e-09, 1.78325021e-09,\n",
              "         3.10658786e-14, 3.44951082e-11, 2.25699832e-08, 8.11462371e-07,\n",
              "         1.87369853e-09, 3.01399261e-09, 1.91888572e-09, 1.31767692e-07,\n",
              "         1.45303744e-07, 3.33613144e-07, 1.03738529e-08, 8.24141693e-21,\n",
              "         1.52226567e-21, 2.32669363e-27, 2.05264018e-14],\n",
              "        [5.60201883e-01, 1.11719100e-02, 1.56692360e-02, 5.07336335e-05,\n",
              "         1.43966720e-01, 2.29187422e-02, 3.45591865e-02, 3.05640865e-02,\n",
              "         1.00730557e-03, 2.91145151e-03, 5.79012372e-03, 1.87484659e-02,\n",
              "         4.94005382e-02, 9.99875965e-07, 4.66670608e-05, 1.18304917e-03,\n",
              "         6.99338038e-04, 2.09086686e-02, 2.69826110e-02, 2.08733487e-03,\n",
              "         3.06260884e-02, 2.14321961e-04, 3.00448830e-03, 1.19566557e-03,\n",
              "         7.42843476e-09, 7.48782622e-05, 4.81793936e-03, 1.51469221e-03,\n",
              "         3.10714636e-03, 4.40784823e-03, 1.38521637e-03, 7.48460996e-04,\n",
              "         3.81450513e-06, 2.14685351e-05, 8.74042053e-06, 1.97125132e-07,\n",
              "         5.38992632e-20, 4.44584688e-26, 8.38044164e-26],\n",
              "        [1.88720946e-06, 1.40965590e-02, 1.48173645e-01, 1.19736446e-02,\n",
              "         1.18106000e-01, 4.18809168e-02, 6.50071055e-02, 8.54815617e-02,\n",
              "         2.23225169e-02, 3.66313122e-02, 3.13652890e-06, 2.10410003e-02,\n",
              "         3.48396599e-02, 5.46953920e-03, 6.58011213e-02, 5.64957708e-02,\n",
              "         3.52163166e-02, 1.38743712e-06, 5.20048626e-02, 3.48852426e-02,\n",
              "         3.46526876e-02, 4.53492217e-02, 4.36429754e-02, 4.36966548e-06,\n",
              "         1.00723654e-02, 8.76614917e-03, 9.87252065e-07, 1.27569190e-03,\n",
              "         6.42096211e-07, 3.60767416e-07, 4.80762935e-07, 3.03513252e-06,\n",
              "         5.51010482e-03, 1.28630502e-03, 6.96554252e-07, 6.46823082e-07,\n",
              "         7.32904883e-12, 2.05897663e-13, 6.24919495e-19],\n",
              "        [1.92458322e-03, 4.39803908e-03, 3.20078544e-02, 1.71841748e-04,\n",
              "         6.95480220e-03, 3.57782628e-05, 1.76614121e-05, 3.80236859e-04,\n",
              "         1.10535592e-01, 2.76780367e-01, 1.84917299e-05, 1.78805459e-02,\n",
              "         6.92888908e-03, 2.17751741e-01, 1.58313778e-03, 1.41074388e-05,\n",
              "         9.55486577e-03, 1.09353301e-03, 4.12383210e-03, 2.01670349e-01,\n",
              "         1.42495364e-05, 2.66049225e-02, 7.20126042e-03, 1.01427540e-05,\n",
              "         8.24105939e-07, 2.31150109e-02, 1.34349350e-04, 4.43933159e-02,\n",
              "         5.77547553e-06, 5.54554827e-05, 4.19957223e-06, 2.15157808e-04,\n",
              "         5.03827096e-08, 2.04740409e-05, 4.39736806e-03, 1.22295216e-06,\n",
              "         5.07058770e-11, 2.12590062e-23, 1.42459135e-12],\n",
              "        [2.57804334e-01, 2.46580876e-03, 2.12698113e-02, 3.14073045e-10,\n",
              "         1.54956561e-02, 1.26791390e-04, 1.35530513e-07, 4.25117370e-03,\n",
              "         1.60464179e-03, 1.14711607e-02, 6.06998568e-03, 2.44581476e-02,\n",
              "         6.35630012e-01, 1.74159936e-07, 2.35290554e-05, 5.21295451e-09,\n",
              "         1.64000376e-05, 2.25193030e-03, 1.99806411e-03, 1.86375645e-03,\n",
              "         8.68494972e-05, 9.76103092e-06, 9.30765737e-03, 2.98484112e-04,\n",
              "         2.97942606e-04, 2.91709748e-05, 1.40405318e-03, 1.53301036e-04,\n",
              "         8.13939609e-04, 3.76665266e-04, 1.30880071e-04, 2.55127728e-04,\n",
              "         1.93716275e-07, 3.45042317e-05, 1.51143438e-11, 4.37752168e-10,\n",
              "         4.27060777e-17, 2.26125821e-19, 2.10061063e-21],\n",
              "        [7.35741423e-06, 3.34045105e-02, 1.90624475e-01, 7.09975185e-03,\n",
              "         2.60431282e-02, 2.90658586e-02, 1.41460365e-02, 6.65530339e-02,\n",
              "         3.32317241e-02, 2.14642614e-01, 2.34411818e-05, 3.89536619e-02,\n",
              "         1.35171656e-02, 1.73968408e-04, 4.31696773e-02, 4.99023544e-03,\n",
              "         6.92022964e-02, 3.31981596e-06, 4.04455885e-02, 3.09233218e-02,\n",
              "         5.50670875e-03, 8.74835700e-02, 3.72320898e-02, 4.77557705e-06,\n",
              "         1.68949959e-03, 2.38182768e-03, 3.15684315e-06, 5.14320738e-04,\n",
              "         1.27910505e-06, 8.64252627e-07, 6.43483588e-07, 1.06937762e-06,\n",
              "         8.32976960e-03, 6.18040678e-04, 6.41100257e-07, 1.05881018e-05,\n",
              "         5.08226057e-12, 9.26926396e-13, 3.72517461e-20],\n",
              "        [1.88173532e-10, 9.05696675e-02, 1.40688261e-08, 8.59257638e-01,\n",
              "         1.80026982e-02, 1.37300454e-02, 4.34209142e-06, 4.11932901e-12,\n",
              "         2.72168393e-07, 1.68458797e-07, 1.07891744e-10, 1.54955359e-07,\n",
              "         4.68762735e-08, 1.75678805e-02, 2.60520522e-07, 2.24949599e-06,\n",
              "         3.82035932e-06, 2.68401950e-11, 6.75737276e-04, 2.43940508e-06,\n",
              "         2.67440271e-07, 3.48226692e-08, 1.00974695e-08, 1.15234482e-12,\n",
              "         6.59259285e-07, 1.57508548e-04, 4.23726939e-12, 2.16221743e-08,\n",
              "         1.05715653e-12, 4.46548874e-12, 2.25045555e-13, 4.15838934e-12,\n",
              "         1.29543842e-08, 2.15945529e-05, 2.45900901e-06, 1.79445315e-12,\n",
              "         9.65270041e-19, 1.97685987e-12, 1.61121990e-21],\n",
              "        [1.58293173e-01, 1.04222563e-04, 5.33985555e-01, 1.40323173e-04,\n",
              "         1.78278031e-04, 5.33384457e-03, 1.45400790e-07, 8.58537015e-03,\n",
              "         2.35173162e-02, 7.41604120e-02, 1.37335351e-02, 1.61317337e-04,\n",
              "         1.83814263e-03, 2.38663401e-03, 8.25996685e-05, 2.28062388e-04,\n",
              "         9.06644091e-02, 3.60548520e-03, 6.64115069e-04, 4.59347008e-04,\n",
              "         1.82280764e-05, 6.17047064e-02, 2.52082624e-04, 1.48701179e-03,\n",
              "         3.19130777e-05, 4.52662149e-04, 5.09408396e-03, 3.86776141e-04,\n",
              "         5.17343311e-03, 6.41926983e-03, 5.40396395e-05, 6.94907852e-04,\n",
              "         3.14517547e-06, 3.68352312e-06, 1.85557838e-07, 1.01565034e-04,\n",
              "         1.16225737e-10, 3.04516781e-14, 1.74849231e-18],\n",
              "        [7.66933024e-01, 4.34517628e-03, 6.61389786e-05, 4.08260617e-04,\n",
              "         1.43223195e-04, 1.29510998e-03, 5.54458983e-02, 1.86482328e-04,\n",
              "         2.55600185e-06, 1.58530984e-05, 8.54147673e-02, 1.74992572e-04,\n",
              "         2.82608642e-04, 4.73439577e-04, 8.82217228e-06, 9.35265874e-08,\n",
              "         2.25399941e-04, 2.60936916e-02, 1.13426126e-03, 2.90156459e-05,\n",
              "         1.72068528e-08, 1.10713881e-06, 1.43064611e-07, 9.60936770e-03,\n",
              "         1.16685510e-06, 1.59691739e-11, 2.59644501e-02, 3.11259762e-04,\n",
              "         8.38700403e-03, 9.34743416e-03, 2.17942079e-03, 1.51985092e-03,\n",
              "         1.04705300e-10, 1.00136233e-09, 4.21947233e-09, 2.86261193e-09,\n",
              "         8.73143246e-15, 2.51446176e-18, 1.58430759e-20],\n",
              "        [3.99001738e-06, 5.54043055e-03, 9.39332396e-02, 8.35207775e-02,\n",
              "         8.98307264e-02, 5.61595745e-02, 5.86718693e-02, 1.32918805e-01,\n",
              "         2.33149305e-02, 1.30621223e-02, 2.77840136e-05, 1.98317654e-02,\n",
              "         5.20345047e-02, 7.82905426e-03, 6.51701093e-02, 2.84399576e-02,\n",
              "         5.79363331e-02, 5.20256435e-06, 1.86166391e-02, 4.40455750e-02,\n",
              "         2.13484839e-02, 7.74504840e-02, 2.91790944e-02, 1.52458870e-05,\n",
              "         5.96052362e-03, 5.30670537e-03, 4.88415117e-06, 1.54381699e-03,\n",
              "         3.12209977e-06, 1.48426432e-06, 2.45440447e-06, 1.38693376e-05,\n",
              "         6.93560019e-03, 1.33474858e-03, 5.32017293e-06, 8.36104221e-07,\n",
              "         6.06798667e-10, 3.29252207e-12, 2.94795093e-18],\n",
              "        [2.89978486e-10, 2.21833996e-02, 1.04529336e-08, 3.62762481e-01,\n",
              "         3.27282697e-02, 2.12778747e-02, 5.09798944e-01, 2.75987688e-11,\n",
              "         2.89998725e-02, 9.57090962e-10, 2.39459258e-10, 6.23327367e-07,\n",
              "         6.60084136e-15, 7.84491841e-03, 8.57091038e-08, 1.16157345e-03,\n",
              "         1.32415518e-02, 1.12683651e-09, 1.92062501e-07, 1.27692303e-07,\n",
              "         3.48414318e-11, 9.19941954e-08, 4.26242401e-08, 3.14034458e-11,\n",
              "         2.39810949e-12, 2.12167035e-13, 3.06239756e-10, 7.32069849e-10,\n",
              "         2.23978735e-11, 6.52135290e-11, 3.58064516e-11, 5.81251505e-11,\n",
              "         7.95501651e-11, 1.64689790e-11, 6.29465772e-13, 1.19851976e-11,\n",
              "         2.84270085e-13, 2.18484249e-18, 1.09753991e-10],\n",
              "        [6.18131876e-01, 8.34061473e-04, 1.66022161e-04, 2.29475781e-01,\n",
              "         4.98413399e-04, 1.94899226e-03, 6.96093659e-04, 3.29070666e-04,\n",
              "         2.96422001e-03, 9.29274969e-03, 1.96180902e-02, 1.87818632e-02,\n",
              "         1.99146423e-04, 3.16592157e-02, 5.23246638e-03, 4.25655162e-06,\n",
              "         8.74231569e-03, 1.47329236e-03, 1.68724146e-04, 7.91726852e-05,\n",
              "         9.71515663e-03, 3.74037365e-04, 5.76255319e-04, 3.16024874e-04,\n",
              "         3.29655508e-04, 1.94571976e-06, 8.88511946e-04, 6.50127092e-03,\n",
              "         4.76208632e-04, 6.37495366e-04, 1.19553279e-05, 2.96346266e-02,\n",
              "         6.43636741e-11, 3.97790063e-06, 2.36480744e-04, 6.18133583e-07,\n",
              "         3.19906775e-12, 4.51945557e-22, 2.62221920e-18],\n",
              "        [1.70072399e-05, 2.18842234e-02, 1.86436355e-01, 1.30240098e-02,\n",
              "         5.50541282e-02, 6.94000674e-03, 9.79068875e-02, 9.69741046e-02,\n",
              "         1.93819497e-02, 4.49747173e-03, 9.13803888e-05, 2.49921158e-02,\n",
              "         3.51303928e-02, 1.70543361e-02, 7.25229308e-02, 4.79798131e-02,\n",
              "         2.26426646e-02, 3.70870184e-05, 6.26318455e-02, 1.93237662e-02,\n",
              "         1.36420177e-02, 8.95827785e-02, 5.81494868e-02, 1.56026435e-05,\n",
              "         1.50814662e-02, 3.99041129e-03, 3.38314530e-05, 1.14731735e-03,\n",
              "         2.68913154e-05, 7.02171201e-06, 3.12456214e-05, 1.43084535e-05,\n",
              "         6.56792708e-03, 7.02577829e-03, 1.46338556e-04, 1.51225140e-05,\n",
              "         8.55014615e-10, 1.61426167e-14, 1.42440568e-16],\n",
              "        [2.62803354e-07, 8.46598864e-01, 3.86035515e-09, 8.14232975e-03,\n",
              "         4.25276048e-02, 1.99384466e-02, 1.72885650e-09, 1.05552758e-07,\n",
              "         4.21643481e-02, 5.01868308e-05, 3.98377935e-08, 1.20776277e-02,\n",
              "         7.48878015e-10, 2.40257364e-02, 1.22273903e-07, 4.47270926e-03,\n",
              "         7.88821012e-07, 5.85965871e-08, 3.93116269e-11, 1.68770484e-07,\n",
              "         1.02234360e-10, 1.17807865e-07, 1.17004828e-09, 1.69419545e-09,\n",
              "         1.78765185e-14, 6.97032492e-12, 2.04375841e-08, 1.45090070e-07,\n",
              "         1.35860068e-09, 2.69559441e-09, 1.38071432e-09, 3.50191307e-08,\n",
              "         4.10211634e-08, 1.81904227e-07, 1.64991620e-09, 2.30293949e-20,\n",
              "         1.44912511e-20, 4.53920811e-27, 3.76948940e-14]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predicted token ID (Tensor)\n",
        "y_pred = tf.argmax(logits[0, -1])  # logits shape: [1, seq_len, vocab_size]\n",
        "\n",
        "# Convert to Python int\n",
        "pred_id = y_pred.numpy()\n",
        "\n",
        "# Access vocabulary safely\n",
        "vocab = text_vec_layer.get_vocabulary()\n",
        "predicted_char = vocab[pred_id + 2]  # Only if you know +2 is correct\n",
        "print(predicted_char)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rmMusraOT1n",
        "outputId": "e1d6179d-bbc7-455a-db34-2bd9ff33c0e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3145fc12"
      },
      "source": [
        "Now that we have the loaded model and can predict the next character, we can write a function to generate a sequence of text."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_probas = tf.math.log([.5,.5,.1])\n",
        "log_probas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "regg28EiOd1v",
        "outputId": "650b50aa-9b9d-4943-a662-7348750c205e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([-0.6931472, -0.6931472, -2.3025851], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "tf.random.categorical(tf.reshape(log_probas, [1, -1]), num_samples=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPS0lYJRPPk1",
        "outputId": "9e35d20a-a563-43c8-ed7e-4de53e0d9bcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 8), dtype=int64, numpy=array([[0, 1, 0, 2, 1, 1, 0, 1]])>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def next_char(text,temperature=1):\n",
        "  outputs = infer(text_vectorization_input=tf.constant([text]))\n",
        "  logits = outputs['sequential'][:, -1, :] # Select logits for the last character\n",
        "  rescaled_logits = logits / temperature # Use logits directly for temperature scaling\n",
        "  char_id = tf.random.categorical(rescaled_logits,num_samples=1)[0,0]\n",
        "  return text_vec_layer.get_vocabulary()[char_id.numpy()+2] # Convert char_id to numpy scalar"
      ],
      "metadata": {
        "id": "dQ4-S_dWPZYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ada26db"
      },
      "source": [
        "def generate_text(text, n_chars=200, temperature=1):\n",
        "    for _ in range(n_chars):\n",
        "        text += next_char(text, temperature)\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "print(generate_text(\"To be or not to be\",temperature=0.01))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zxZsHKiQzF2",
        "outputId": "8dcbe8e7-9f0b-4f9e-dffe-3929f9288712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To be or not to be the duke\n",
            "as it is a proper and the duke is a proper and the contents\n",
            "as the strange provost, and the duke of your honour.\n",
            "\n",
            "provost:\n",
            "i will not be a strange daughter is a strange daughter\n",
            "to the death\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "2fb2ce6a",
        "outputId": "7cacdd94-ce02-4a48-f09a-46e8378361c0"
      },
      "source": [
        "!pip install gradio -q\n",
        "import gradio as gr\n",
        "\n",
        "def gradio_generate_text(prompt, n_chars=200, temperature=1):\n",
        "    # Reuse the existing generate_text function\n",
        "    return generate_text(prompt, n_chars, temperature)\n",
        "\n",
        "# Define the Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=gradio_generate_text,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Prompt\", value=\"To be or not to be\"),\n",
        "        gr.Slider(minimum=50, maximum=500, value=200, label=\"Number of characters to generate\"),\n",
        "        gr.Slider(minimum=0.01, maximum=2.0, value=1.0, label=\"Temperature\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Generated Text\", lines=10), # Added lines parameter to increase height\n",
        "    title=\"Shakespearean Text Generator\",\n",
        "    description=\"Generate text in the style of Shakespeare using a trained RNN model.\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "interface.launch()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://5209335bc6b37e3cab.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5209335bc6b37e3cab.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}